{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import copy\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10, MNIST, QMNIST\n",
        "from torchvision.transforms.transforms import Resize\n",
        "from typing import Any, Callable, Dict, List, Optional, Tuple\n",
        "import os\n",
        "import os.path\n",
        "import pickle\n",
        "from typing import Any, Callable, Optional, Tuple\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision.datasets.utils import check_integrity, download_and_extract_archive\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision"
      ],
      "metadata": {
        "id": "cG4YqSpboPjh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Architectures.** For experiments on CIFAR-10, CIFAR-100 and CINIC-10, we use a variant of ResNet-18 (He et al., 2016). We adapted the ResNet18 to 32x32 images by modifying the architecture to remove the downsampling effect. We replaced the spatial downsampling of a strided convolution and max pooling in the original ResNet18, with a convolutional layer with 64 filters and a kernel size of 3x3. We also removed the average pooling at the end of the ResNet18. This ResNet18 variant is similar to Resnet20, just with more filters\n",
        "\n",
        "**Resnet Architecture as mentioned in paper:** [ https://github.com/OATML/RHO-Loss/blob/4c88851742ce5397153f4fef80abd4682958ac56/src/models/modules/resnet_cifar.py#L86 ]\n"
      ],
      "metadata": {
        "id": "kP6alw6HoEpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            planes, planes, kernel_size=3, stride=1, padding=1, bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    in_planes,\n",
        "                    self.expansion * planes,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False,\n",
        "                ),\n",
        "                nn.BatchNorm2d(self.expansion * planes),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            planes, self.expansion * planes, kernel_size=1, bias=False\n",
        "        )\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    in_planes,\n",
        "                    self.expansion * planes,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False,\n",
        "                ),\n",
        "                nn.BatchNorm2d(self.expansion * planes),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "def ResNet152():\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
        "\n",
        "def test():\n",
        "    net = ResNet18()\n",
        "    y = net(torch.randn(1, 3, 32, 32))\n",
        "    print(y.size())\n",
        "\n",
        "def resnet18_imagenet(pretrained=False, classes=10):\n",
        "    model = torchvision.models.resnet18(pretrained=pretrained, num_classes=1000)\n",
        "    model.conv1 = nn.Conv2d(\n",
        "        3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
        "    )\n",
        "    model.maxpool = nn.Identity()\n",
        "    model.fc = nn.Linear(512, classes, bias=True)\n",
        "    return model\n",
        "\n",
        "def resnet50_imagenet(pretrained=False, classes=10):\n",
        "    model = torchvision.models.resnet50(pretrained=pretrained, num_classes=1000)\n",
        "    model.fc = nn.Linear(512, classes, bias=True)\n",
        "    return model"
      ],
      "metadata": {
        "id": "6BWegLUWoBmu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data loading, data splitting code from: https://github.com/OATML/RHO-Loss/blob/main/src/datamodules/datamodules.py , https://github.com/OATML/RHO-Loss/blob/main/src/datamodules/datasets/sequence_datasets.py\n",
        "\n"
      ],
      "metadata": {
        "id": "BTe-EMQ3n31V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class indices_CIFAR10(VisionDataset):\n",
        "    base_folder = \"cifar-10-batches-py\"\n",
        "    url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
        "    filename = \"cifar-10-python.tar.gz\"\n",
        "    tgz_md5 = \"c58f30108f718f92721af3b95e74349a\"\n",
        "    train_list = [\n",
        "        [\"data_batch_1\", \"c99cafc152244af753f735de768cd75f\"],\n",
        "        [\"data_batch_2\", \"d4bba439e000b95fd0a9bffe97cbabec\"],\n",
        "        [\"data_batch_3\", \"54ebc095f3ab1f0389bbae665268c751\"],\n",
        "        [\"data_batch_4\", \"634d18415352ddfa80567beed471001a\"],\n",
        "        [\"data_batch_5\", \"482c414d41f54cd18b22e5b47cb7c3cb\"],\n",
        "    ]\n",
        "\n",
        "    test_list = [\n",
        "        [\"test_batch\", \"40351d587109b95175f43aff81a1287e\"],\n",
        "    ]\n",
        "    meta = {\n",
        "        \"filename\": \"batches.meta\",\n",
        "        \"key\": \"label_names\",\n",
        "        \"md5\": \"5ff9c542aee3614f3951f8cda6e48888\",\n",
        "    }\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        root: str,\n",
        "        train: bool = True,\n",
        "        transform: Optional[Callable] = None,\n",
        "        target_transform: Optional[Callable] = None,\n",
        "        sequence=None,\n",
        "    ) -> None:\n",
        "\n",
        "        super(indices_CIFAR10, self).__init__(\n",
        "            root, transform=transform, target_transform=target_transform\n",
        "        )\n",
        "\n",
        "        self.train = train  # training set or test set\n",
        "\n",
        "        self.download()\n",
        "\n",
        "        if not self._check_integrity():\n",
        "            raise RuntimeError(\n",
        "                \"Dataset not found or corrupted even though we tried to download it\"\n",
        "            )\n",
        "\n",
        "        if self.train:\n",
        "            downloaded_list = self.train_list\n",
        "        else:\n",
        "            downloaded_list = self.test_list\n",
        "\n",
        "        self.data: Any = []\n",
        "        self.targets = []\n",
        "\n",
        "        # now load the picked numpy arrays\n",
        "        for file_name, checksum in downloaded_list:\n",
        "            file_path = os.path.join(self.root, self.base_folder, file_name)\n",
        "            with open(file_path, \"rb\") as f:\n",
        "                entry = pickle.load(f, encoding=\"latin1\")\n",
        "                self.data.append(entry[\"data\"])\n",
        "                if \"labels\" in entry:\n",
        "                    self.targets.extend(entry[\"labels\"])\n",
        "                else:\n",
        "                    self.targets.extend(entry[\"fine_labels\"])\n",
        "\n",
        "        self.data = np.vstack(self.data).reshape(-1, 3, 32, 32)\n",
        "        self.data = self.data.transpose((0, 2, 3, 1))  # convert to HWC\n",
        "\n",
        "        self._load_meta()\n",
        "        if sequence is not None:\n",
        "            self.sequence = sequence\n",
        "        else:\n",
        "            self.sequence = np.arange(len(self.data))\n",
        "\n",
        "    def _load_meta(self) -> None:\n",
        "        path = os.path.join(self.root, self.base_folder, self.meta[\"filename\"])\n",
        "        if not check_integrity(path, self.meta[\"md5\"]):\n",
        "            raise RuntimeError(\"Dataset metadata file not found or corrupted\")\n",
        "        with open(path, \"rb\") as infile:\n",
        "            data = pickle.load(infile, encoding=\"latin1\")\n",
        "            self.classes = data[self.meta[\"key\"]]\n",
        "        self.class_to_idx = {_class: i for i, _class in enumerate(self.classes)}\n",
        "\n",
        "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index\n",
        "        Returns:\n",
        "            tuple: (image, target) where target is index of the target class.\n",
        "        \"\"\"\n",
        "        img, target = self.data[self.sequence[index]], self.targets[self.sequence[index]]\n",
        "\n",
        "        # doing this so that it is consistent with all other datasets\n",
        "        # to return a PIL Image\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return index, img, target\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.sequence)\n",
        "\n",
        "    def _check_integrity(self) -> bool:\n",
        "        root = self.root\n",
        "        for fentry in self.train_list + self.test_list:\n",
        "            filename, md5 = fentry[0], fentry[1]\n",
        "            fpath = os.path.join(root, self.base_folder, filename)\n",
        "            if not check_integrity(fpath, md5):\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def download(self) -> None:\n",
        "        if self._check_integrity():\n",
        "            print(\"Files already downloaded and verified\")\n",
        "            return\n",
        "        download_and_extract_archive(\n",
        "            self.url, self.root, filename=self.filename, md5=self.tgz_md5\n",
        "        )\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return \"Split: {}\".format(\"Train\" if self.train is True else \"Test\")\n",
        "\n",
        "class CIFAR10DataModule:\n",
        "    def __init__(self, data_dir=\"./data\", batch_size=960, test_batch_size=100, num_workers=4):\n",
        "        self.data_dir = data_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.test_batch_size = test_batch_size\n",
        "        self.num_workers = num_workers\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "        ])\n",
        "        self.data_aug_transform = transforms.Compose([\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "        ])\n",
        "\n",
        "    def setup(self, double_irlomo=False):\n",
        "        full_dataset = indices_CIFAR10(self.data_dir, train=True, transform=self.data_aug_transform)\n",
        "\n",
        "        indices = list(range(len(full_dataset)))\n",
        "        train_indices = indices[::2]\n",
        "        val_indices = indices[1::2]\n",
        "\n",
        "        self.train_split_1 = Subset(full_dataset, train_indices)\n",
        "        self.train_split_2 = Subset(full_dataset, val_indices)\n",
        "        self.train_split_2_indices = val_indices  # needed for irreducible loss tracking\n",
        "\n",
        "        self.test_dataset = indices_CIFAR10(self.data_dir, train=False, transform=self.transform)\n",
        "\n",
        "    def get_train_loader_split1(self):\n",
        "        return DataLoader(self.train_split_1, batch_size=128, shuffle=True, num_workers=self.num_workers)\n",
        "\n",
        "    def get_train_loader_split2(self):\n",
        "        return DataLoader(self.train_split_2, batch_size=1, shuffle=False, num_workers=self.num_workers)\n",
        "\n",
        "    def get_test_loader(self):\n",
        "        return DataLoader(self.test_dataset, batch_size=self.test_batch_size, shuffle=False, num_workers=self.num_workers)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "p6SZSo9GfyOa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training IL Model:**\n",
        "\n",
        "> **Data augmentation:** On CIFAR-10, CIFAR-100, and CINIC-10, we train using data augmentation (random crop and horizontal flip), both for training the IL model, and in the main training runs. Remember that we only compute the irreducible losses once at the start of training.\n",
        "\n",
        "> We can efficiently compute the IL with an “irreducible loss model\" (IL model) that is smaller than the target model and has low accuracy . ResNet18 IL model trained for 37x fewer steps than each target model.\n",
        "\n",
        "Irreducible loss models can be small and cheap. In our\n",
        "default setting, both the target model and IL model have the same architecture (ResNet-18).The smaller IL model accelerates training as much or more than the larger model, even though its final accuracy is far lower than the target ResNet18 (11.5% lower on CIFAR-10, 7% on CIFAR-100, and 8.1% on CINIC-10).\n",
        "\n"
      ],
      "metadata": {
        "id": "Yl_iVs3Tnyoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === CONTINUATION CODE: RHO-LOSS Training on CIFAR-10 ===\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm, trange\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ====== Set device and seed ======\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ====== Initialize DataModule and Prepare Splits ======\n",
        "dm = CIFAR10DataModule()\n",
        "dm.setup()\n",
        "\n",
        "train_loader_il = dm.get_train_loader_split1()\n",
        "eval_loader_il = dm.get_train_loader_split2()\n",
        "test_loader = dm.get_test_loader()\n",
        "train_ids = dm.train_split_2_indices\n",
        "\n",
        "# ====== Step 1: Train IL Model ======\n",
        "il_model = ResNet18().to(device)\n",
        "il_optimizer = optim.AdamW(il_model.parameters(), lr=1e-3)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in trange(30, desc=\"Training IL Model\"):\n",
        "    il_model.train()\n",
        "    correct, total = 0, 0\n",
        "    for _, x, y in train_loader_il:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        il_optimizer.zero_grad()\n",
        "        logits = il_model(x)\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        il_optimizer.step()\n",
        "        correct += (logits.argmax(1) == y).sum().item()\n",
        "        total += y.size(0)\n",
        "    acc = 100.0 * correct / total\n",
        "    print(f\"[IL Model] Epoch {epoch+1}: Accuracy = {acc:.2f}%\")\n",
        "    if acc >= 65.0:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ip5ENzzjo2Z4",
        "outputId": "c3475f4e-9d15-4dbb-e066-61345c1a4a10"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training IL Model:   3%|▎         | 1/30 [00:21<10:11, 21.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IL Model] Epoch 1: Accuracy = 41.74%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining IL Model:   7%|▋         | 2/30 [00:42<09:51, 21.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IL Model] Epoch 2: Accuracy = 58.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining IL Model:   7%|▋         | 2/30 [01:04<14:58, 32.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[IL Model] Epoch 3: Accuracy = 66.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compute Irreducible Loss**"
      ],
      "metadata": {
        "id": "_2hE9mJzo7rj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Computing irreducible loss on split_2...\")\n",
        "il_model.eval()\n",
        "irreducible_loss = {}\n",
        "with torch.no_grad():\n",
        "    for idx, (_, x, y) in tqdm(zip(train_ids, eval_loader_il), total=len(train_ids), desc=\"Computing IL\"):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        loss = F.cross_entropy(il_model(x), y).item()\n",
        "        irreducible_loss[idx] = loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yz9RIo-o6pz",
        "outputId": "2e0fd886-4f67-409d-b465-22da55f0088b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing irreducible loss on split_2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing IL: 100%|██████████| 25000/25000 [02:25<00:00, 171.94it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Target Model with RHO-LOSS**\n",
        "\n",
        "> **Hyperparameters:** All models are trained using the AdamW optimizer with default PyTorch hyperparameters (β1=0.9, β2=0.999, and weight decay of 0.01, learning rate 0.001), a nb = 32 ( nB = 320 , meaning we select nB/nb = 10% of points.We use between 2 and 10 seeds for each experiment\n"
      ],
      "metadata": {
        "id": "Pu611-uSpB1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Step 3: Train Target Model with RHO-LOSS ======\n",
        "target_model = ResNet18().to(device)\n",
        "target_optimizer = optim.AdamW(target_model.parameters(), lr=1e-3)\n",
        "topk = 32\n",
        "reached_80 = reached_875 = False\n",
        "\n",
        "for epoch in trange(1, 300, desc=\"Training Target Model\"):\n",
        "    target_model.train()\n",
        "    random.shuffle(train_ids)\n",
        "    for i in range(0, len(train_ids), 320):\n",
        "        ids = train_ids[i:i+320]\n",
        "        x_b, y_b, il_b = [], [], []\n",
        "        for idx in ids:\n",
        "            _, x, y = dm.train_split_2.dataset[idx]\n",
        "            x_b.append(x)\n",
        "            y_b.append(y)\n",
        "            il_b.append(irreducible_loss[idx])\n",
        "\n",
        "        if len(x_b) < topk:\n",
        "            continue  # skip if batch too small\n",
        "\n",
        "        x_tensor = torch.stack(x_b).to(device)\n",
        "        y_tensor = torch.tensor(y_b).to(device)\n",
        "        il_tensor = torch.tensor(il_b).to(device)\n",
        "\n",
        "        logits = target_model(x_tensor)\n",
        "        losses = F.cross_entropy(logits, y_tensor, reduction='none')\n",
        "        rho = losses - il_tensor\n",
        "        top_indices = torch.topk(rho, topk).indices\n",
        "        selected_loss = losses[top_indices].mean()\n",
        "\n",
        "        target_optimizer.zero_grad()\n",
        "        selected_loss.backward()\n",
        "        target_optimizer.step()\n",
        "\n",
        "    # ====== Evaluate on Test Set ======\n",
        "    target_model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for _, x, y in test_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = target_model(x).argmax(1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    acc = 100.0 * correct / total\n",
        "    print(f\"[Target Model] Epoch {epoch}: Accuracy = {acc:.2f}%\")\n",
        "    if not reached_80 and acc >= 80.0:\n",
        "        print(f\"✅ Reached 80% at epoch {epoch}\")\n",
        "        reached_80 = True\n",
        "    if not reached_875 and acc >= 87.5:\n",
        "        print(f\"✅ Reached 87.5% at epoch {epoch}\")\n",
        "        reached_875 = True\n",
        "    if reached_80 and reached_875:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df5z1jz2iHx2",
        "outputId": "46ec3078-e059-4d5b-8a89-20516b5c5763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Target Model:   0%|          | 1/299 [00:22<1:53:44, 22.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 1: Accuracy = 32.71%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:   1%|          | 2/299 [00:45<1:52:43, 22.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 2: Accuracy = 42.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:   1%|          | 3/299 [01:08<1:52:45, 22.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 3: Accuracy = 45.96%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:   1%|▏         | 4/299 [01:31<1:53:12, 23.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 4: Accuracy = 44.66%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:   2%|▏         | 5/299 [01:55<1:53:43, 23.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 5: Accuracy = 48.82%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:   2%|▏         | 6/299 [02:18<1:53:53, 23.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 6: Accuracy = 61.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:   2%|▏         | 7/299 [02:42<1:53:27, 23.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 7: Accuracy = 62.06%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:   3%|▎         | 8/299 [03:05<1:52:41, 23.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 8: Accuracy = 62.78%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:   3%|▎         | 9/299 [03:28<1:51:57, 23.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 9: Accuracy = 66.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:   3%|▎         | 10/299 [03:51<1:51:15, 23.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 10: Accuracy = 63.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:   4%|▎         | 11/299 [04:14<1:50:36, 23.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 11: Accuracy = 67.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:   4%|▍         | 12/299 [04:37<1:50:06, 23.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 12: Accuracy = 71.39%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:   4%|▍         | 13/299 [05:00<1:49:38, 23.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 13: Accuracy = 71.39%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:   5%|▍         | 14/299 [05:23<1:50:06, 23.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 14: Accuracy = 72.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:   5%|▌         | 15/299 [05:46<1:49:26, 23.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 15: Accuracy = 70.96%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:   5%|▌         | 16/299 [06:09<1:49:16, 23.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 16: Accuracy = 70.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:   6%|▌         | 17/299 [06:33<1:49:28, 23.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 17: Accuracy = 74.18%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:   6%|▌         | 18/299 [06:57<1:49:28, 23.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 18: Accuracy = 73.74%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:   6%|▋         | 19/299 [07:20<1:48:58, 23.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 19: Accuracy = 73.75%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:   7%|▋         | 20/299 [07:43<1:48:21, 23.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 20: Accuracy = 73.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:   7%|▋         | 21/299 [08:06<1:47:35, 23.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 21: Accuracy = 74.35%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:   7%|▋         | 22/299 [08:29<1:46:52, 23.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 22: Accuracy = 76.39%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:   8%|▊         | 23/299 [08:52<1:46:16, 23.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 23: Accuracy = 75.72%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:   8%|▊         | 24/299 [09:15<1:45:43, 23.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 24: Accuracy = 75.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:   8%|▊         | 25/299 [09:38<1:45:09, 23.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 25: Accuracy = 76.06%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:   9%|▊         | 26/299 [10:01<1:44:39, 23.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 26: Accuracy = 74.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:   9%|▉         | 27/299 [10:24<1:44:31, 23.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 27: Accuracy = 76.81%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:   9%|▉         | 28/299 [10:48<1:44:42, 23.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 28: Accuracy = 75.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:  10%|▉         | 29/299 [11:11<1:44:47, 23.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 29: Accuracy = 77.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:  10%|█         | 30/299 [11:34<1:44:24, 23.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 30: Accuracy = 77.29%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:  10%|█         | 31/299 [11:57<1:43:38, 23.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 31: Accuracy = 77.21%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:  11%|█         | 32/299 [12:20<1:42:58, 23.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 32: Accuracy = 78.66%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:  11%|█         | 33/299 [12:43<1:42:18, 23.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 33: Accuracy = 78.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:  11%|█▏        | 34/299 [13:06<1:41:41, 23.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 34: Accuracy = 77.36%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:  12%|█▏        | 35/299 [13:29<1:41:11, 23.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 35: Accuracy = 77.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:  12%|█▏        | 36/299 [13:52<1:40:46, 22.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 36: Accuracy = 79.89%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:  12%|█▏        | 37/299 [14:15<1:40:22, 22.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 37: Accuracy = 76.34%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:  13%|█▎        | 38/299 [14:38<1:40:28, 23.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 38: Accuracy = 78.93%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:  13%|█▎        | 39/299 [15:02<1:40:43, 23.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 39: Accuracy = 79.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:  13%|█▎        | 40/299 [15:26<1:40:37, 23.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 40: Accuracy = 79.23%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:  14%|█▎        | 41/299 [15:49<1:40:14, 23.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 41: Accuracy = 80.08%\n",
            "✅ Reached 80% at epoch 41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:  14%|█▍        | 42/299 [16:12<1:39:30, 23.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 42: Accuracy = 79.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:  14%|█▍        | 43/299 [16:35<1:38:47, 23.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 43: Accuracy = 78.93%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:  15%|█▍        | 44/299 [16:58<1:38:10, 23.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 44: Accuracy = 80.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:  15%|█▌        | 45/299 [17:21<1:37:37, 23.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 45: Accuracy = 79.65%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:  15%|█▌        | 46/299 [17:44<1:37:08, 23.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 46: Accuracy = 81.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Target Model:  16%|█▌        | 47/299 [18:07<1:36:43, 23.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Target Model] Epoch 47: Accuracy = 77.92%\n"
          ]
        }
      ]
    }
  ]
}